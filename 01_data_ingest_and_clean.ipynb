{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed95a264",
   "metadata": {},
   "source": [
    "# Data ingest & Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca8b33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aeff73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAW_DATA_PATH = '../data/raw/' \n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "TARGET_QUARTER_DIR = 'faers_ascii_2024q4' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc8c4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Column definitions (no changes needed) ---\n",
    "DEMO_COLS = ['primaryid', 'caseid', 'caseversion', 'sex', 'age', 'occr_country', 'init_fda_dt']\n",
    "DRUG_COLS = ['primaryid', 'drug_seq', 'drugname', 'role_cod']\n",
    "REAC_COLS = ['primaryid', 'pt'] # 'pt' is the MedDRA Preferred Term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c4755",
   "metadata": {},
   "source": [
    "\n",
    "# Data Loading and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cd623f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing quarter: faers_ascii_2024q4 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_faers_file(filepath, columns):\n",
    "    \"\"\"Loads a single FAERS ASCII file, correctly handling the lack of a header.\"\"\"\n",
    "    df = pd.read_csv(\n",
    "        filepath, delimiter='$', header=None, names=columns, usecols=columns,\n",
    "        low_memory=False, on_bad_lines='warn'\n",
    "    )\n",
    "    if 'init_fda_dt' in df.columns:\n",
    "        df.rename(columns={'init_fda_dt': 'receiptdate'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "print(f\"--- Processing quarter: {TARGET_QUARTER_DIR} ---\")\n",
    "quarter_path = os.path.join(RAW_DATA_PATH, TARGET_QUARTER_DIR, 'ascii')\n",
    "\n",
    "demo_file = glob.glob(os.path.join(quarter_path, 'DEMO*.txt'))\n",
    "drug_file = glob.glob(os.path.join(quarter_path, 'DRUG*.txt'))\n",
    "reac_file = glob.glob(os.path.join(quarter_path, 'REAC*.txt'))\n",
    "\n",
    "if not (demo_file and drug_file and reac_file):\n",
    "    print(f\"❌ ERROR: Could not find all required files in {quarter_path}\")\n",
    "else:\n",
    "    df_demo = load_faers_file(demo_file[0], DEMO_COLS)\n",
    "    df_drug = load_faers_file(drug_file[0], DRUG_COLS)\n",
    "    df_reac = load_faers_file(reac_file[0], REAC_COLS)\n",
    "\n",
    "    # Merge, Clean, and Filter\n",
    "    merged_df = pd.merge(df_demo, df_drug, on='primaryid', how='left')\n",
    "    final_df = pd.merge(merged_df, df_reac, on='primaryid', how='left')\n",
    "    df_clean = final_df[final_df['role_cod'] == 'PS'].copy()\n",
    "    df_clean.dropna(subset=['drugname', 'pt'], inplace=True)\n",
    "    df_clean['drugname'] = df_clean['drugname'].str.upper().str.strip()\n",
    "    df_clean = df_clean.sort_values('caseversion', ascending=True)\n",
    "    df_clean = df_clean.drop_duplicates(subset=['primaryid', 'drugname', 'pt'], keep='last')\n",
    "\n",
    "    # --- Create analysis-ready dataset (one row per report) ---\n",
    "    df_analysis_ready = df_clean.groupby('primaryid').agg({\n",
    "        'drugname': lambda x: sorted(list(set(x))),\n",
    "        'pt': lambda x: sorted(list(set(x)))\n",
    "    }).reset_index()\n",
    "    df_analysis_ready.rename(columns={'primaryid': 'safetyreportid', 'drugname': 'drugs', 'pt': 'reactions'}, inplace=True)\n",
    "\n",
    "    # --- Create clean demographics dataset (for deep dives) ---\n",
    "    df_demo_clean = df_clean[['primaryid', 'age', 'sex', 'occr_country', 'receiptdate']].drop_duplicates(subset=['primaryid'])\n",
    "    df_demo_clean.rename(columns={'primaryid': 'safetyreportid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f4760",
   "metadata": {},
   "source": [
    "\n",
    "# Save Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42a7ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Success! Clean data saved to:\n",
      "1. faers_faers_ascii_2024q4_analysis_ready.parquet (for signal detection)\n",
      "2. faers_faers_ascii_2024q4_demographics_clean.parquet (for deep dive analysis)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        os.makedirs(PROCESSED_DATA_PATH)\n",
    "\n",
    "# Save the two essential output files\n",
    "analysis_output = f'faers_{TARGET_QUARTER_DIR}_analysis_ready.parquet'\n",
    "demo_output = f'faers_{TARGET_QUARTER_DIR}_demographics_clean.parquet'\n",
    "    \n",
    "df_analysis_ready.to_parquet(os.path.join(PROCESSED_DATA_PATH, analysis_output))\n",
    "df_demo_clean.to_parquet(os.path.join(PROCESSED_DATA_PATH, demo_output))\n",
    "\n",
    "print(f\"\\n✅ Success! Clean data saved to:\")\n",
    "print(f\"1. {analysis_output} (for signal detection)\")\n",
    "print(f\"2. {demo_output} (for deep dive analysis)\")\n",
    "\n",
    "\n",
    "# --- Markdown Cell: Conclusion ---\n",
    "# # Conclusion\n",
    "#\n",
    "# We have successfully transformed the raw, disparate text files into two clean, structured datasets. This foundational step ensures that all subsequent analysis is built on reliable, high-quality data. We are now ready to begin the search for safety signals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
